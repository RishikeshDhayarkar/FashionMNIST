# -*- coding: utf-8 -*-
"""fashionMNIST_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/1trIQXYXGxJaxUDN6liCSH66fM0lysvLM
"""

import torch 
import torch.nn as nn 
import torch.nn.functional as F
import torchvision
import torchvision.transforms as transforms
import numpy as np
import matplotlib.pyplot as plt
import torch.optim as optim

train_set = torchvision.datasets.FashionMNIST(root='./data/FashionMNIST',
                                              train=True, #we want the data for training set
                                              download=True, # download data if its not specifies in the root
                                              transform=transforms.Compose([transforms.ToTensor()])) # transform the training set into pytorch tensors

train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)

len(train_set)

train_set.train_labels

train_set.train_labels.bincount()

sample = next(iter(train_set))

len(sample)

type(sample)

image, label = sample

plt.imshow(image.squeeze(), cmap='gray')
label

batch = next(iter(train_loader))

len(batch)

type(batch)

images, labels = batch

images.shape

labels.shape

grid = torchvision.utils.make_grid(images, nrow=10)
plt.figure(figsize=(20,20))
plt.imshow(np.transpose(grid, (1,2,0)))
labels

"""pytorch's nn library gives us the tools to construct layers of an NN. Each layer has tranformation and weights.

  Here according to OOPS- a transformation will be a method(code) and
                                weights will be attributes(data)

 The class Module is the base class for all NN modules. So, all the layers and NN(a bunch of layers) inherit the features of 'Module' class
"""

class Network(nn.Module):
  def __init__(self):
    super(Network, self).__init__()
    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)
    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)

    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)
    self.fc2 = nn.Linear(in_features=120, out_features=60)
    self.out = nn.Linear(in_features=60, out_features=10)

  def forward(self, t):
    # (1) Input layer
    t=t

    # (2) Hidden conv layer
    t=self.conv1(t)
    t=F.relu(t)
    t=F.max_pool2d(t, kernel_size=2, stride=2)

    # (3) Hidden conv layer
    t=self.conv2(t)
    t=F.relu(t)
    t=F.max_pool2d(t, kernel_size=2, stride=2)

    # (4) Hidden Linear layer
    t=t.reshape(-1, 12*4*4)
    t=self.fc1(t)
    t=F.relu(t)

    # (5) Hidden Linear layer
    t=self.fc2(t)
    t=F.relu(t)

    # (6) Output layer
    t=self.out(t)
    
    return t

network = Network()

for name, param in network.named_parameters():
  print(name, '\t\t', param.shape)

torch.set_grad_enabled(True)

image.shape

image.unsqueeze(0).shape

pred = network(image.unsqueeze(0))

pred.shape

pred

pred.argmax(dim=1)

F.softmax(pred, dim=1)

F.softmax(pred, dim=1).argmax(dim=1)

preds = network(images)

preds.shape

preds # Batch size = 10 with 10 prediction classes

preds.argmax(dim=1)

labels

preds.argmax(dim=1).eq(labels).sum()

def get_num_correct(preds, labels):
  return preds.argmax(dim=1).eq(labels).sum().item()

get_num_correct(preds, labels)

loss = F.cross_entropy(preds, labels)
loss.item()

print(network.conv1.weight.grad) # Because we havent back propagated yet. The gradients will be generated once we backpropagate.

loss.backward() # Calculating the gradients

network.conv1.weight.grad.shape

network.conv1.weight.shape

network.conv2.weight.grad.shape

network.conv2.weight.shape

"""The shape of the gradient tensor of a layer is same as that of weights tensor of that particular layer. To adjust every single weight value we need a unique gradient for each weight."""

optimizer = optim.Adam(network.parameters(), lr=0.01) # Creating an optimizer

loss.item()

optimizer.step() # Updating the weights

preds = network(images)
loss = F.cross_entropy(preds, labels)

loss.item()

"""The loss value got reduced from 2.321 to 2.304. This because the weights got modified."""

get_num_correct(preds, labels)

"""Number of correct predictions increased from 8 to 15"""

