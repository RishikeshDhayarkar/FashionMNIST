{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "fashionMNIST_2.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "3TjiiN6qSWoG",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c42b3ebf-8c77-4af7-cf1d-8f154efaf6f1"
      },
      "source": [
        "import torch \n",
        "import torch.nn as nn \n",
        "import torch.nn.functional as F\n",
        "import torchvision\n",
        "import torchvision.transforms as transforms\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.optim as optim\n",
        "\n",
        "torch.set_grad_enabled(True)"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<torch.autograd.grad_mode.set_grad_enabled at 0x7f9ecc772828>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 2
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yTwfq5kwSuHZ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_num_correct(preds, labels):\n",
        "  return preds.argmax(dim=1).eq(labels).sum().item()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMfpKPTsS0mJ",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "class Network(nn.Module):\n",
        "  def __init__(self):\n",
        "    super(Network, self).__init__()\n",
        "    self.conv1 = nn.Conv2d(in_channels=1, out_channels=6, kernel_size=5)\n",
        "    self.conv2 = nn.Conv2d(in_channels=6, out_channels=12, kernel_size=5)\n",
        "\n",
        "    self.fc1 = nn.Linear(in_features=12*4*4, out_features=120)\n",
        "    self.fc2 = nn.Linear(in_features=120, out_features=60)\n",
        "    self.out = nn.Linear(in_features=60, out_features=10)\n",
        "\n",
        "  def forward(self, t):\n",
        "    # (1) Input layer\n",
        "    t=t\n",
        "\n",
        "    # (2) Hidden conv layer\n",
        "    t=self.conv1(t)\n",
        "    t=F.relu(t)\n",
        "    t=F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # (3) Hidden conv layer\n",
        "    t=self.conv2(t)\n",
        "    t=F.relu(t)\n",
        "    t=F.max_pool2d(t, kernel_size=2, stride=2)\n",
        "\n",
        "    # (4) Hidden Linear layer\n",
        "    t=t.reshape(-1, 12*4*4)\n",
        "    t=self.fc1(t)\n",
        "    t=F.relu(t)\n",
        "\n",
        "    # (5) Hidden Linear layer\n",
        "    t=self.fc2(t)\n",
        "    t=F.relu(t)\n",
        "\n",
        "    # (6) Output layer\n",
        "    t=self.out(t)\n",
        "    \n",
        "    return t"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tpB7jrZGTEFW",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 272
        },
        "outputId": "21c0ff42-6a0f-4f0a-bdfd-9e701403abf0"
      },
      "source": [
        "train_set = torchvision.datasets.FashionMNIST(root='./data/FashionMNIST',\n",
        "                                              train=True, \n",
        "                                              download=True, \n",
        "                                              transform=transforms.Compose([transforms.ToTensor()])) "
      ],
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "  0%|          | 16384/26421880 [00:00<03:00, 146407.28it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "26427392it [00:00, 76387966.68it/s]                            \n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "32768it [00:00, 454632.21it/s]\n",
            "  2%|â–         | 98304/4422102 [00:00<00:04, 895225.86it/s]"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n",
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/train-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "4423680it [00:00, 21921201.88it/s]                         \n",
            "8192it [00:00, 111627.18it/s]\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n",
            "Extracting ./data/FashionMNIST/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to ./data/FashionMNIST/FashionMNIST/raw\n",
            "Processing...\n",
            "Done!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6rYuyr5BTKRc",
        "colab_type": "text"
      },
      "source": [
        "<h2>Training with a single batch</h2>"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMcwzfD6TR6I",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 101
        },
        "outputId": "3879ec84-8cf2-4e51-9841-71db55b0dcd9"
      },
      "source": [
        "network = Network()\n",
        "\n",
        "train_loader = torch.utils.data.DataLoader(train_set, batch_size=100)\n",
        "optimizer = optim.Adam(network.parameters(), lr=0.01)\n",
        "\n",
        "\n",
        "for epoch in range(5):\n",
        "  \n",
        "  total_loss = 0\n",
        "  total_correct = 0\n",
        "\n",
        "  for batch in train_loader:\n",
        "    images, labels = batch\n",
        "\n",
        "    preds = network(images)\n",
        "    loss = F.cross_entropy(preds, labels) # Calculate loss\n",
        "    \n",
        "    optimizer.zero_grad()\n",
        "    loss.backward() #Calculate gradients\n",
        "    optimizer.step() #Update weights\n",
        "\n",
        "    total_loss += loss.item()\n",
        "    total_correct += get_num_correct(preds, labels)\n",
        "\n",
        "  print('epoch:', epoch, 'total_correct:', total_correct, 'loss:', total_loss)"
      ],
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "epoch: 0 total_correct: 46521 loss: 350.3630883693695\n",
            "epoch: 1 total_correct: 51225 loss: 237.73708787560463\n",
            "epoch: 2 total_correct: 52009 loss: 215.0774446427822\n",
            "epoch: 3 total_correct: 52288 loss: 208.53166519105434\n",
            "epoch: 4 total_correct: 52615 loss: 199.48026624321938\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "raAcLpYPhTJA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "c6a65b71-8eed-4687-b236-a0c115d77577"
      },
      "source": [
        "total_correct / len(train_set)"
      ],
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.8769166666666667"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3lVIxeWCFf41",
        "colab_type": "text"
      },
      "source": [
        "Getting predictions for the complete training set, without gradients and backpropagation. The code till here trains the model using gradients and backprop but now that we want to just get the predictions we can turn the gradient tracking feature off. The weights that were calculated during the 5th epoch are still available in the 'Parameters' of the netowork layers. So, by turning the gradient tracking feature off we are using the previously generated weights to make new predictions. By turning the gradient tracking off the amount of computational resources used will be less."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "r2O-IllcFj71",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def get_all_preds(model, loader):\n",
        "  all_preds = torch.tensor([])\n",
        "  for batch in loader:\n",
        "    images, labels = batch\n",
        "    preds = model(images)\n",
        "    all_preds = torch.cat((all_preds, preds), dim=0)\n",
        "  return all_preds"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7-mRixTqHjVt",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000)\n",
        "train_preds = get_all_preds(network, prediction_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4RTgosiwIL7p",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "db90ba49-c54e-4735-9d49-dfcebf289a63"
      },
      "source": [
        "train_preds.shape"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rKhSAMmcJHqu",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "5277ea99-a68e-48fa-996c-56f453a106fc"
      },
      "source": [
        "print(train_preds.requires_grad) # Tells if gradient tracking feature is enabled or not. Here this returns True because gradient tracking is enabled globally."
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "True\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_24T6aj8KDRn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_preds.grad # Generates no output because there no backpropagation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "miUpTTC0KZRr",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "67f03029-0554-462a-d83e-51a515aee156"
      },
      "source": [
        "train_preds.grad_fn # Since the gradient tracking feature is turned on initially(in the imports section) pytorch tries to keep track of the gradient\n",
        "# tensor, even though the gradient tensor is empty"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<CatBackward at 0x7f9ecc23b4e0>"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vUVK6YBkL0G3",
        "colab_type": "text"
      },
      "source": [
        "There are 2 ways of turning off gradients 1) Turn it of globally(check the import cell)\n",
        "\n",
        "2) Turn if locally with 'torch.no_grad()' function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_yQQPLDiMGx6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "with torch.no_grad():\n",
        "  prediction_loader = torch.utils.data.DataLoader(train_set, batch_size=10000)\n",
        "  train_preds = get_all_preds(network, prediction_loader)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "C7z3nDAnMQ5X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "57773436-b1db-419b-8b1c-1821272dcdec"
      },
      "source": [
        "train_preds.shape"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j2q9BTlmMmoB",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "95030ae5-6ed0-41e1-cae5-18a71c183ff3"
      },
      "source": [
        "print(train_preds.requires_grad) # Tells if gradient tracking feature is enabled or not. Here this returns False because gradient tracking is disabled locally."
      ],
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "False\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ryWCvnHzMTxX",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_preds.grad # Generates no output because there no backpropagation"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "D2VcMcAYMVon",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "train_preds.grad_fn # Generates no output because pytorch is not keeping track of the gradient tensor"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YoB8xrBjMchK",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 50
        },
        "outputId": "3990bbcb-1e54-4c34-cae0-f8703490b567"
      },
      "source": [
        "preds_correct = get_num_correct(train_preds, train_set.targets)\n",
        "print('Total correct predictions = ', preds_correct)\n",
        "print('Accuracy = ', preds_correct/ len(train_set))"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Total correct predictions =  52894\n",
            "Accuracy =  0.8815666666666667\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JIn8TbgJPSww",
        "colab_type": "text"
      },
      "source": [
        "Building a confusion matrix manually(without using the function from sklearn)"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WeBiQocPPaQn",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "7acc8f22-2337-49ff-b921-27ca964a9266"
      },
      "source": [
        "train_preds.shape"
      ],
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 10])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3iwMLUrPh7E",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "b7a44225-ac3e-476e-bdb6-3d30e3c4988d"
      },
      "source": [
        "train_preds.argmax(dim=1)"
      ],
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 0, 0,  ..., 3, 0, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 21
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VAyazcCJPqeJ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "36eed0df-707a-4faf-e089-42af6493fa2a"
      },
      "source": [
        "train_set.targets"
      ],
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([9, 0, 0,  ..., 3, 0, 5])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 22
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VrVk5xS2Ps8r",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9ce38138-50f2-4bc9-f4fe-2a120e93491c"
      },
      "source": [
        "train_preds.argmax(dim=1).shape"
      ],
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 23
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "y0G4Pk-UQHX2",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "8ad733c2-3ce6-4161-a801-5dc299f9aa6b"
      },
      "source": [
        "train_set.targets.shape"
      ],
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 24
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xKd-uCnKQKWN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "stacked = torch.stack((train_set.targets, train_preds.argmax(dim=1)), dim=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fLUo-10qQyy3",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "9492f103-c8ec-453f-88f3-b5f1f1e21150"
      },
      "source": [
        "stacked.shape"
      ],
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([60000, 2])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 26
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "lFBMsIgWQ0Z1",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 134
        },
        "outputId": "a1acc7cd-01fa-497b-b0cb-0b0414e67e75"
      },
      "source": [
        "stacked"
      ],
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[9, 9],\n",
              "        [0, 0],\n",
              "        [0, 0],\n",
              "        ...,\n",
              "        [3, 3],\n",
              "        [0, 0],\n",
              "        [5, 5]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 27
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "APsOLK-tQ9Vx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "734be9d3-49f0-47e4-a4bf-cc62b07fb75b"
      },
      "source": [
        "cmat = torch.zeros(10, 10, dtype=torch.int64)\n",
        "cmat"
      ],
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
              "        [0, 0, 0, 0, 0, 0, 0, 0, 0, 0]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 28
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sUGMUtV1RV6x",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "for pair in stacked:\n",
        "  tar, pr = pair.tolist()\n",
        "  cmat[tar, pr] = cmat[tar, pr]+1"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "etlWvH3dR_e9",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "81a65782-6d4a-4860-a686-b77ecfcd6090"
      },
      "source": [
        "cmat"
      ],
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "tensor([[5526,    1,   49,   68,    9,    0,  319,    0,   28,    0],\n",
              "        [  30, 5851,    2,   74,    6,    2,   33,    0,    2,    0],\n",
              "        [  61,    1, 4433,   62,  771,    0,  643,    0,   29,    0],\n",
              "        [ 330,   15,    4, 5333,  156,    0,  160,    0,    2,    0],\n",
              "        [  13,    2,  257,  210, 4852,    0,  652,    0,   14,    0],\n",
              "        [   2,    0,    2,    5,    0, 5746,    1,  166,    7,   71],\n",
              "        [1321,    2,  399,   89,  415,    0, 3747,    0,   27,    0],\n",
              "        [   0,    0,    0,    0,    0,   31,    0, 5769,    5,  195],\n",
              "        [  43,    4,   15,   22,   21,    2,   82,    7, 5804,    0],\n",
              "        [   0,    0,    0,    1,    0,   16,    1,  147,    2, 5833]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 30
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "K79CZPZlSIZ0",
        "colab_type": "text"
      },
      "source": [
        "Creating confusion matrix using a built-in function"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "NMScgBKbSOB7",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from sklearn.metrics import confusion_matrix"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2EXxB0rASnIq",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "cm = confusion_matrix(train_set.targets, train_preds.argmax(dim=1))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "8WluqCCjTTiq",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 185
        },
        "outputId": "a422147c-e163-46ac-d90d-f060912858d3"
      },
      "source": [
        "cm"
      ],
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([[5526,    1,   49,   68,    9,    0,  319,    0,   28,    0],\n",
              "       [  30, 5851,    2,   74,    6,    2,   33,    0,    2,    0],\n",
              "       [  61,    1, 4433,   62,  771,    0,  643,    0,   29,    0],\n",
              "       [ 330,   15,    4, 5333,  156,    0,  160,    0,    2,    0],\n",
              "       [  13,    2,  257,  210, 4852,    0,  652,    0,   14,    0],\n",
              "       [   2,    0,    2,    5,    0, 5746,    1,  166,    7,   71],\n",
              "       [1321,    2,  399,   89,  415,    0, 3747,    0,   27,    0],\n",
              "       [   0,    0,    0,    0,    0,   31,    0, 5769,    5,  195],\n",
              "       [  43,    4,   15,   22,   21,    2,   82,    7, 5804,    0],\n",
              "       [   0,    0,    0,    1,    0,   16,    1,  147,    2, 5833]])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 33
        }
      ]
    }
  ]
}